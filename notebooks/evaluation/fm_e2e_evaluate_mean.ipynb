{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import utils as U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../models/evaluation/MeanEstimator_1122.csv\")\n",
    "model_name = \"MeanEstimator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"absolute_error\"] = np.abs(df.y_pred - df.y_true)\n",
    "melted_df = df[[\"attraction\", \"y_true\", \"y_pred\"]].melt(id_vars=[\"attraction\"])\n",
    "nonan_df = df.dropna(axis=\"index\", how=\"any\", subset=[\"y_true\", \"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    df,\n",
    "    x=\"attraction\",\n",
    "    y=\"absolute_error\",\n",
    "    title=(\n",
    "        f\"Absolute E2E Prediction Errors of {model_name} on the test set<br>\"\n",
    "        \"<sup>each point is the absolute prediction error for a specific date, time and attraction</sup>\"\n",
    "    ),\n",
    "    labels={\"absolute_error\": \"absolute error (min)\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    melted_df,\n",
    "    x=\"attraction\",\n",
    "    y=\"value\",\n",
    "    color=\"variable\",\n",
    "    title=\"E2E predicted vs actual waiting times per attraction\",\n",
    "    labels={\"value\": \"waiting time (min)\", \"variable\": \"type\"},\n",
    "    height=500,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.regression_scatter_plot(nonan_df, \n",
    "    [\"Chiapas DIE Wasserbahn\", \"River Quest\", \"Crazy Bats\", \"Taron\", \"F.L.Y.\"], f\"E2E {model_name} (test set)\", col_wrap=3, width=1200, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.regression_scatter_plot(\n",
    "    nonan_df,\n",
    "    [\n",
    "        \"Bolles Flugschule\",\n",
    "        \"Feng Ju Palace\",\n",
    "        \"Verrücktes Hotel Tartüff\",\n",
    "        \"Würmling Express\",\n",
    "        \"Black Mamba\",\n",
    "        \"Wellenflug\",\n",
    "    ],\n",
    "    f\"E2E {model_name} (test set)\",\n",
    "    col_wrap=3,\n",
    "    width=1200,\n",
    "    height=800,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_metrics = U.regression_metrics(nonan_df.y_true, nonan_df.y_pred)\n",
    "print(f\"missing prediction: {(~df.y_true.isna() & df.y_pred.isna()).sum()/len(df):.2%}\")\n",
    "print(f\"spurious prediction: {(df.y_true.isna() & ~df.y_pred.isna()).sum()/len(df):.2%}\")\n",
    "print(f\"y_true and y_pred NaN: {(df.y_true.isna() & df.y_pred.isna()).sum()/len(df):.2%}\")\n",
    "print(f\"r2 score: {reg_metrics['r2']:.3f}\")\n",
    "print(f\"root mean squared error: {reg_metrics['rmse']:.2f}\")\n",
    "print(f\"mean absolute error: {reg_metrics['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../models/evaluation/LGBMRegressor_Production_1122.csv\")\n",
    "model_name = \"LGBMRegressor/Production\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"absolute_error\"] = np.abs(df.y_pred - df.y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    df,\n",
    "    x=\"attraction\",\n",
    "    y=\"absolute_error\",\n",
    "    title=(\n",
    "        f\"Absolute E2E Prediction Errors of {model_name} on the test set<br>\"\n",
    "        \"<sup>each point is the absolute prediction error for a specific date, time and attraction</sup>\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_without_nan_df = df[[\"y_true\", \"y_pred\"]].dropna(axis=\"index\", how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_metrics = U.regression_metrics(y_without_nan_df.y_true, y_without_nan_df.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"missing prediction: {(~df.y_true.isna() & df.y_pred.isna()).sum()/len(df):.2%}\")\n",
    "print(f\"spurious prediction: {(df.y_true.isna() & ~df.y_pred.isna()).sum()/len(df):.2%}\")\n",
    "print(f\"y_true and y_pred NaN: {(df.y_true.isna() & df.y_pred.isna()).sum()/len(df):.2%}\")\n",
    "print(f\"r2 score: {reg_metrics['r2']:.3f}\")\n",
    "print(f\"root mean squared error: {reg_metrics['rmse']:.2f}\")\n",
    "print(f\"mean absolute error: {reg_metrics['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(U.MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.sklearn.load_model(\"../../mlruns/0/51eb21015ac34b9faaf7486691bfe2e7/artifacts/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = U.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8eb5555b6276951b53cb1dac65bc4059c32d03fe323d11af090506d873ab16c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
